{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e1fa907-f005-4c55-844f-8ad7729276dc",
   "metadata": {},
   "source": [
    "# Compute confidence intervals for predictions on test set using CV+\n",
    "Created by Ivan Lima on Sun Feb  5 2023 13:06:58 -0500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d66b01b3-9162-4d1c-bd00-191edf6af9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated on Mon Feb  6 22:03:57 2023\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os, datetime, warnings\n",
    "print('Last updated on {}'.format(datetime.datetime.now().ctime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba6c9c43-16a3-4ffd-a6d1-b322c9d9d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sns_settings\n",
    "sns.set_context('paper')\n",
    "pd.options.display.max_columns = 50\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8184a36d-6b51-4d70-a52d-3759de18ed2c",
   "metadata": {},
   "source": [
    "## Load DIC bottle data & select features & target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d919971-6609-4fe1-97d2-27cbfe68b7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bottle_dic = pd.read_csv('data/bottle_data_DIC_prepared.csv', parse_dates=['Date'],\n",
    "                            index_col=0, na_values=['<undefined>',-9999.])\n",
    "df_bottle_dic = df_bottle_dic.loc[df_bottle_dic.Oxygen_flag.isin([2, 6])]\n",
    "df_bottle_dic = df_bottle_dic.loc[df_bottle_dic.Oxygen.notnull()]\n",
    "df_bottle_dic['log_Chl'] = np.log(df_bottle_dic.Chl)\n",
    "df_bottle_dic['log_KD490'] = np.log(df_bottle_dic.KD490)\n",
    "\n",
    "features = ['Depth', 'Temperature', 'Salinity', 'Oxygen', 'pCO2_atm', 'ADT', 'SST_hires', 'log_KD490']\n",
    "target = ['DIC']\n",
    "\n",
    "suffix = 'all_vars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83fe780e-f6f7-4358-a090-b86c49669c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bottle_dic = pd.read_csv('data/bottle_data_DIC_prepared.csv', parse_dates=['Date'],\n",
    "#                             index_col=0, na_values=['<undefined>',-9999.])\n",
    "# df_bottle_dic['log_Chl'] = np.log(df_bottle_dic.Chl)\n",
    "# df_bottle_dic['log_KD490'] = np.log(df_bottle_dic.KD490)\n",
    "\n",
    "# features = ['Depth', 'Temperature', 'Salinity', 'pCO2_atm', 'ADT', 'SST_hires', 'log_KD490']\n",
    "# target = ['DIC']\n",
    "\n",
    "# suffix = 'noO2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b88c7dc-c795-4823-8763-56f9f54755fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bottle_dic = pd.read_csv('data/bottle_data_DIC_prepared.csv', parse_dates=['Date'],\n",
    "#                             index_col=0, na_values=['<undefined>',-9999.])\n",
    "# df_bottle_dic['log_Chl'] = np.log(df_bottle_dic.Chl)\n",
    "# df_bottle_dic['log_KD490'] = np.log(df_bottle_dic.KD490)\n",
    "\n",
    "# features = ['Depth', 'Temperature', 'Salinity', 'pCO2_atm']\n",
    "# target = ['DIC']\n",
    "\n",
    "# suffix = 'nosat'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defdb703-5697-4fd8-a19a-5508a2fdf610",
   "metadata": {},
   "source": [
    "## Split data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac04521c-6bb5-4e23-b1ca-d2704963563a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3970, 8), (2977, 8), (993, 8), (2977, 1), (993, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "data = df_bottle_dic[features + target + ['Season']].dropna()\n",
    "\n",
    "X = data[features].values\n",
    "y = data[target].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=data.Season.values, random_state=77)\n",
    "X.shape, X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f0d3aa-4a8f-477c-a7a2-daf144ff13dc",
   "metadata": {},
   "source": [
    "## Compute confidence intervals using CV+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca6ef552-61e4-4f2e-a9b7-f00975bc505e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 22:04:00.071045: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 01/10 test set R squared: 0.962\n",
      "Fold 02/10 test set R squared: 0.963\n",
      "Fold 03/10 test set R squared: 0.963\n",
      "Fold 04/10 test set R squared: 0.963\n",
      "Fold 05/10 test set R squared: 0.964\n",
      "Fold 06/10 test set R squared: 0.965\n",
      "Fold 07/10 test set R squared: 0.961\n",
      "Fold 08/10 test set R squared: 0.964\n",
      "Fold 09/10 test set R squared: 0.966\n",
      "Fold 10/10 test set R squared: 0.964\n",
      "\n",
      "Best R squared:  0.966\n",
      "Worst R squared: 0.961\n",
      "Mean R squared:  0.964\n",
      "\n",
      "Execution time = 1.47 minutes\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "\n",
    "keras.utils.set_random_seed(42) # make things reproducible\n",
    "n_hidden = 256 # number of nodes in hidden layers\n",
    "alpha=0.01\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(n_hidden, input_shape=X_train.shape[1:]),\n",
    "    keras.layers.LeakyReLU(alpha=alpha),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(n_hidden),\n",
    "    keras.layers.LeakyReLU(alpha=alpha),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(y_train.shape[1])\n",
    "])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)\n",
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam())\n",
    "\n",
    "score_vals = []       # store score values\n",
    "y_test_pred_list = [] # store predictions\n",
    "resid = []            # store residuals\n",
    "\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "start = time.time()\n",
    "\n",
    "for k, (train_idx, test_idx) in enumerate(kf.split(X_train)):\n",
    "    X_tr, X_te = X_train[train_idx], X_train[test_idx]\n",
    "    y_tr, y_te = y_train[train_idx], y_train[test_idx]\n",
    "    history = model.fit(X_tr, y_tr, epochs=700, verbose=0, validation_split=0.2, callbacks=[early_stopping_cb])\n",
    "    y_pred = model.predict(X_test) # predictons on test set\n",
    "    y_test_pred_list.append(y_pred.ravel())\n",
    "    resid.append((y_te - model.predict(X_te)).ravel()) # residuals on sub test set\n",
    "    score = r2_score(y_test, y_pred)\n",
    "    score_vals.append(score)\n",
    "    print('Fold {:02}/{} test set R squared: {:.3f}'.format(k+1, n_splits, score))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "scores = np.array(score_vals)\n",
    "print('\\nBest R squared:  {:.3f}'.format(scores.max()))\n",
    "print('Worst R squared: {:.3f}'.format(scores.min()))\n",
    "print('Mean R squared:  {:.3f}'.format(scores.mean()))\n",
    "\n",
    "print('\\nExecution time = {:.2f} minutes'.format((end-start)/60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a83cf6e-56dd-4b0d-8959-1f7b4a10aa4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "writing results/ci095_all_vars.csv\n"
     ]
    }
   ],
   "source": [
    "percentile = 0.95\n",
    "cv_preds = np.array(y_test_pred_list).transpose()\n",
    "residuals = np.concatenate([x for x in resid])\n",
    "ci = np.quantile(residuals, percentile)\n",
    "if ci > 0:\n",
    "    lower_bound = [np.quantile(cv_preds[n] - ci, percentile) for n in range(cv_preds.shape[0])]\n",
    "    upper_bound = [np.quantile(cv_preds[n] + ci, percentile) for n in range(cv_preds.shape[0])]\n",
    "else:\n",
    "    lower_bound = [np.quantile(cv_preds[n] + ci, percentile) for n in range(cv_preds.shape[0])]\n",
    "    upper_bound = [np.quantile(cv_preds[n] - ci, percentile) for n in range(cv_preds.shape[0])]\n",
    "\n",
    "df_ci = pd.DataFrame({'DIC_observed':y_test.ravel(), 'lower_bound': lower_bound, 'upper_bound': upper_bound})\n",
    "\n",
    "outfile = 'results/ci{:03d}_{}.csv'.format(int(percentile * 100), suffix)\n",
    "print('\\nwriting {}'.format(outfile))\n",
    "df_ci.to_csv(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16b68bf5-521c-412d-859d-e3001991a625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 33\n",
      "19.415566406249933\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    df_ci.loc[df_ci.DIC_observed < df_ci.lower_bound].shape[0],\n",
    "    df_ci.loc[df_ci.DIC_observed > df_ci.upper_bound].shape[0]\n",
    ")\n",
    "print(ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b53425f-28c8-4fed-81b8-9967461badce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ensemble = pd.read_csv('results/ensemble_preds_dic_all_vars.csv', index_col=0)\n",
    "# df = df_ensemble.drop('DIC_observed', axis=1)\n",
    "# ensemble_preds = df.values\n",
    "\n",
    "# lower_bound = [np.quantile(ensemble_preds[n], 0.05) for n in range(ensemble_preds.shape[0])]\n",
    "# upper_bound = [np.quantile(ensemble_preds[n], 0.95) for n in range(ensemble_preds.shape[0])]\n",
    "# df_ci2 = pd.DataFrame({'DIC_observed':df_ensemble.DIC_observed, 'lower_bound': lower_bound, 'upper_bound': upper_bound})\n",
    "\n",
    "# df_ci2.loc[df_ci2.DIC_observed < df_ci2.lower_bound].shape, df_ci2.loc[df_ci2.DIC_observed > df_ci2.upper_bound].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
