{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54448c96-d005-4c57-a893-5ffd48802782",
   "metadata": {},
   "source": [
    "# Model ensemble to estimate confidence confidence intervals for DIC estimates\n",
    "Created by Ivan Lima on Sat Feb  4 2023 14:33:00 -0500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c8838f-a1db-4bd5-8bb6-6e1693505ecd",
   "metadata": {},
   "source": [
    "In this notebook we use a model ensemble to estimate confidence intervals for DIC predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5746cc70-753e-4eb8-a0b3-84119608426e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated on Tue Feb  7 20:10:59 2023\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os, datetime, warnings\n",
    "print('Last updated on {}'.format(datetime.datetime.now().ctime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a10f8f8-e2c3-49d5-bdfb-ccdcf7929223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sns_settings\n",
    "sns.set_context('paper')\n",
    "pd.options.display.max_columns = 50\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cec08c8-5621-4fcf-896b-cd086ad8a055",
   "metadata": {},
   "source": [
    "## Load DIC bottle data & select features & target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e069dfea-440e-4cd7-8637-e180e60c4a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bottle_dic = pd.read_csv('data/bottle_data_DIC_prepared.csv', parse_dates=['Date'],\n",
    "                            index_col=0, na_values=['<undefined>',-9999.])\n",
    "df_bottle_dic = df_bottle_dic.loc[df_bottle_dic.Oxygen_flag.isin([2, 6])]\n",
    "df_bottle_dic = df_bottle_dic.loc[df_bottle_dic.Oxygen.notnull()]\n",
    "df_bottle_dic['log_Chl'] = np.log(df_bottle_dic.Chl)\n",
    "df_bottle_dic['log_KD490'] = np.log(df_bottle_dic.KD490)\n",
    "\n",
    "features = ['Depth', 'Temperature', 'Salinity', 'Oxygen', 'pCO2_atm', 'ADT', 'SST_hires', 'log_KD490']\n",
    "target = ['DIC']\n",
    "\n",
    "suffix = 'all_vars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bc09f00-ce62-460b-9765-27bb0735c9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bottle_dic = pd.read_csv('data/bottle_data_DIC_prepared.csv', parse_dates=['Date'],\n",
    "#                             index_col=0, na_values=['<undefined>',-9999.])\n",
    "# df_bottle_dic['log_Chl'] = np.log(df_bottle_dic.Chl)\n",
    "# df_bottle_dic['log_KD490'] = np.log(df_bottle_dic.KD490)\n",
    "\n",
    "# features = ['Depth', 'Temperature', 'Salinity', 'pCO2_atm', 'ADT', 'SST_hires', 'log_KD490']\n",
    "# target = ['DIC']\n",
    "\n",
    "# suffix = 'noO2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f36a27bd-8095-4c65-9a5d-60f019f6048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bottle_dic = pd.read_csv('data/bottle_data_DIC_prepared.csv', parse_dates=['Date'],\n",
    "#                             index_col=0, na_values=['<undefined>',-9999.])\n",
    "# df_bottle_dic['log_Chl'] = np.log(df_bottle_dic.Chl)\n",
    "# df_bottle_dic['log_KD490'] = np.log(df_bottle_dic.KD490)\n",
    "\n",
    "# features = ['Depth', 'Temperature', 'Salinity', 'pCO2_atm']\n",
    "# target = ['DIC']\n",
    "\n",
    "# suffix = 'nosat'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9d87de-bf22-495b-a25e-29a774693630",
   "metadata": {},
   "source": [
    "## Split data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8712f864-a85a-4b29-b22d-7b72a54506d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3970, 8), (2977, 8), (993, 8), (2977, 1), (993, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "data = df_bottle_dic[features + target + ['Season']].dropna()\n",
    "\n",
    "X = data[features].values\n",
    "y = data[target].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=data.Season.values, random_state=77)\n",
    "X.shape, X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da18233-8989-4ed1-8e4c-3713363b50a4",
   "metadata": {},
   "source": [
    "## Run model ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a69f5a49-c096-43a2-9cc1-8effa238747a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 20:11:01.652197: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble 001/100 test set R squared = 0.963\n",
      "Ensemble 002/100 test set R squared = 0.963\n",
      "Ensemble 003/100 test set R squared = 0.964\n",
      "Ensemble 004/100 test set R squared = 0.964\n",
      "Ensemble 005/100 test set R squared = 0.964\n",
      "Ensemble 006/100 test set R squared = 0.963\n",
      "Ensemble 007/100 test set R squared = 0.964\n",
      "Ensemble 008/100 test set R squared = 0.964\n",
      "Ensemble 009/100 test set R squared = 0.965\n",
      "Ensemble 010/100 test set R squared = 0.963\n",
      "Ensemble 011/100 test set R squared = 0.964\n",
      "Ensemble 012/100 test set R squared = 0.965\n",
      "Ensemble 013/100 test set R squared = 0.962\n",
      "Ensemble 014/100 test set R squared = 0.965\n",
      "Ensemble 015/100 test set R squared = 0.963\n",
      "Ensemble 016/100 test set R squared = 0.964\n",
      "Ensemble 017/100 test set R squared = 0.963\n",
      "Ensemble 018/100 test set R squared = 0.964\n",
      "Ensemble 019/100 test set R squared = 0.965\n",
      "Ensemble 020/100 test set R squared = 0.963\n",
      "Ensemble 021/100 test set R squared = 0.963\n",
      "Ensemble 022/100 test set R squared = 0.965\n",
      "Ensemble 023/100 test set R squared = 0.964\n",
      "Ensemble 024/100 test set R squared = 0.964\n",
      "Ensemble 025/100 test set R squared = 0.965\n",
      "Ensemble 026/100 test set R squared = 0.965\n",
      "Ensemble 027/100 test set R squared = 0.964\n",
      "Ensemble 028/100 test set R squared = 0.963\n",
      "Ensemble 029/100 test set R squared = 0.965\n",
      "Ensemble 030/100 test set R squared = 0.963\n",
      "Ensemble 031/100 test set R squared = 0.964\n",
      "Ensemble 032/100 test set R squared = 0.963\n",
      "Ensemble 033/100 test set R squared = 0.964\n",
      "Ensemble 034/100 test set R squared = 0.963\n",
      "Ensemble 035/100 test set R squared = 0.965\n",
      "Ensemble 036/100 test set R squared = 0.962\n",
      "Ensemble 037/100 test set R squared = 0.963\n",
      "Ensemble 038/100 test set R squared = 0.963\n",
      "Ensemble 039/100 test set R squared = 0.964\n",
      "Ensemble 040/100 test set R squared = 0.964\n",
      "Ensemble 041/100 test set R squared = 0.964\n",
      "Ensemble 042/100 test set R squared = 0.963\n",
      "Ensemble 043/100 test set R squared = 0.964\n",
      "Ensemble 044/100 test set R squared = 0.963\n",
      "Ensemble 045/100 test set R squared = 0.963\n",
      "Ensemble 046/100 test set R squared = 0.963\n",
      "Ensemble 047/100 test set R squared = 0.963\n",
      "Ensemble 048/100 test set R squared = 0.964\n",
      "Ensemble 049/100 test set R squared = 0.964\n",
      "Ensemble 050/100 test set R squared = 0.964\n",
      "Ensemble 051/100 test set R squared = 0.965\n",
      "Ensemble 052/100 test set R squared = 0.962\n",
      "Ensemble 053/100 test set R squared = 0.964\n",
      "Ensemble 054/100 test set R squared = 0.964\n",
      "Ensemble 055/100 test set R squared = 0.966\n",
      "Ensemble 056/100 test set R squared = 0.965\n",
      "Ensemble 057/100 test set R squared = 0.964\n",
      "Ensemble 058/100 test set R squared = 0.965\n",
      "Ensemble 059/100 test set R squared = 0.964\n",
      "Ensemble 060/100 test set R squared = 0.962\n",
      "Ensemble 061/100 test set R squared = 0.963\n",
      "Ensemble 062/100 test set R squared = 0.964\n",
      "Ensemble 063/100 test set R squared = 0.963\n",
      "Ensemble 064/100 test set R squared = 0.965\n",
      "Ensemble 065/100 test set R squared = 0.964\n",
      "Ensemble 066/100 test set R squared = 0.964\n",
      "Ensemble 067/100 test set R squared = 0.963\n",
      "Ensemble 068/100 test set R squared = 0.964\n",
      "Ensemble 069/100 test set R squared = 0.964\n",
      "Ensemble 070/100 test set R squared = 0.963\n",
      "Ensemble 071/100 test set R squared = 0.964\n",
      "Ensemble 072/100 test set R squared = 0.964\n",
      "Ensemble 073/100 test set R squared = 0.963\n",
      "Ensemble 074/100 test set R squared = 0.963\n",
      "Ensemble 075/100 test set R squared = 0.964\n",
      "Ensemble 076/100 test set R squared = 0.964\n",
      "Ensemble 077/100 test set R squared = 0.963\n",
      "Ensemble 078/100 test set R squared = 0.964\n",
      "Ensemble 079/100 test set R squared = 0.964\n",
      "Ensemble 080/100 test set R squared = 0.965\n",
      "Ensemble 081/100 test set R squared = 0.963\n",
      "Ensemble 082/100 test set R squared = 0.964\n",
      "Ensemble 083/100 test set R squared = 0.963\n",
      "Ensemble 084/100 test set R squared = 0.963\n",
      "Ensemble 085/100 test set R squared = 0.964\n",
      "Ensemble 086/100 test set R squared = 0.963\n",
      "Ensemble 087/100 test set R squared = 0.963\n",
      "Ensemble 088/100 test set R squared = 0.964\n",
      "Ensemble 089/100 test set R squared = 0.963\n",
      "Ensemble 090/100 test set R squared = 0.963\n",
      "Ensemble 091/100 test set R squared = 0.964\n",
      "Ensemble 092/100 test set R squared = 0.964\n",
      "Ensemble 093/100 test set R squared = 0.962\n",
      "Ensemble 094/100 test set R squared = 0.961\n",
      "Ensemble 095/100 test set R squared = 0.964\n",
      "Ensemble 096/100 test set R squared = 0.964\n",
      "Ensemble 097/100 test set R squared = 0.963\n",
      "Ensemble 098/100 test set R squared = 0.964\n",
      "Ensemble 099/100 test set R squared = 0.963\n",
      "Ensemble 100/100 test set R squared = 0.963\n",
      "\n",
      "Execution time = 35.91 minutes\n",
      "\n",
      "Best R squared =  0.966\n",
      "Worst R squared = 0.961\n",
      "Mean R squared =  0.964\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import time\n",
    "\n",
    "# keras.utils.set_random_seed(42) # make things reproducible\n",
    "n_hidden = 256 # number of nodes in hidden layers\n",
    "alpha=0.01\n",
    "\n",
    "base_model = keras.models.Sequential([\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(n_hidden, input_shape=X_train.shape[1:]),\n",
    "    keras.layers.LeakyReLU(alpha=alpha),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(n_hidden),\n",
    "    keras.layers.LeakyReLU(alpha=alpha),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(y_train.shape[1])\n",
    "])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)\n",
    "\n",
    "score_vals = []       # store score values\n",
    "y_test_pred_list = [] # store predictions\n",
    "resid = []            # store residuals\n",
    "\n",
    "start = time.time()\n",
    "ntot = 100 # number of ensemble members\n",
    "\n",
    "for k in range(ntot):\n",
    "    new_model = keras.models.clone_model(base_model) # cloning resets the model weights\n",
    "    new_model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam())\n",
    "    history = new_model.fit(X_train, y_train, epochs=700, verbose=0, validation_split=0.2, callbacks=[early_stopping_cb])\n",
    "    y_pred = new_model.predict(X_test)\n",
    "    y_test_pred_list.append(y_pred.ravel())\n",
    "    # resid.append((y_test - y_pred).ravel()) # compute residuals on test set\n",
    "    score = r2_score(y_test, y_pred)\n",
    "    score_vals.append(score)\n",
    "    print('Ensemble {:03d}/{} test set R squared = {:.3f}'.format(k+1, ntot, score))\n",
    "\n",
    "end = time.time()\n",
    "print('\\nExecution time = {:.2f} minutes'.format((end-start)/60.))\n",
    "\n",
    "scores = np.array(score_vals)\n",
    "print('\\nBest R squared =  {:.3f}'.format(scores.max()))\n",
    "print('Worst R squared = {:.3f}'.format(scores.min()))\n",
    "print('Mean R squared =  {:.3f}'.format(scores.mean()))\n",
    "\n",
    "# save ensemble predictions on test set to CSV file\n",
    "ensemble_preds = np.array(y_test_pred_list).transpose()\n",
    "cols = ['DIC_pred_{:02d}'.format(n+1) for n in range(ensemble_preds.shape[1])]\n",
    "df_ensemble_preds = pd.DataFrame(ensemble_preds, columns=cols)\n",
    "df_ensemble_preds['DIC_observed'] = y_test\n",
    "df_ensemble_preds.to_csv('results/ensemble_preds_dic_{}.csv'.format(suffix))\n",
    "\n",
    "# # save ensemble residuals on test set to CSV file\n",
    "# ensemble_resids = np.array(resid).transpose()\n",
    "# cols = ['DIC_resid_{:02d}'.format(n+1) for n in range(ensemble_resids.shape[1])]\n",
    "# df_ensemble_resids = pd.DataFrame(ensemble_resids, columns=cols)\n",
    "# df_ensemble_resids.to_csv('results/ensemble_resids_dic_{}.csv'.format(suffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85dadc85-1355-4f93-8e80-610b8b0ff3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower_bound = [np.quantile(ensemble_preds[n], 0.05) for n in range(ensemble_preds.shape[0])]\n",
    "# upper_bound = [np.quantile(ensemble_preds[n], 0.95) for n in range(ensemble_preds.shape[0])]\n",
    "# df_ci = pd.DataFrame({'DIC_observed':y_test.ravel(), 'lower_bound': lower_bound, 'upper_bound': upper_bound})\n",
    "# df_ci.loc[df_ci.DIC_observed < df_ci.lower_bound].shape[0], df_ci.loc[df_ci.DIC_observed > df_ci.upper_bound].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "730a85fe-7851-4d62-bc7c-42244e005f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92.37309570312505, 99.79123535156259)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.abs(df_ci.DIC_observed - df_ci.lower_bound).max(), np.abs(df_ci.DIC_observed - df_ci.upper_bound).max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
